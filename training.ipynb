{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-10T12:33:07.605854Z",
     "start_time": "2024-10-10T12:33:03.851555Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import pdist, cdist\n",
    "from scipy.spatial import cKDTree\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import umap\n",
    "from sklearn.manifold import MDS\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from src.models import SpaceNet, RecurrentSpaceNet, Decoder\n",
    "from src.utils import ratemap_collage, SimpleDatasetMaker\n",
    "\n",
    "plt.rcdefaults()\n",
    "plt.style.use(\"figures/project_style.mplstyle\")\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T12:33:08.538392Z",
     "start_time": "2024-10-10T12:33:08.534958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "figure_path = os.path.join(os.getcwd(), \"figures\")\n",
    "model_path = os.path.join(os.getcwd(), \"models\")\n",
    "results_path = os.path.join(os.getcwd(), \"results\")"
   ],
   "id": "aa1282e69a1e7069",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Recurrent Network (no context)",
   "id": "804531ec282af839"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T12:33:13.076658Z",
     "start_time": "2024-10-10T12:33:13.072687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ----------------------- Params -----------------------\n",
    "train_steps = 60000         # Number of training steps\n",
    "timesteps = 10              # Length of trajectories\n",
    "bs = 64                     # Batch size\n",
    "lr = 1e-4                   # Learning rate\n",
    "n_models = 1                # Number of models to train"
   ],
   "id": "1e778adbda58f0f7",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T15:45:06.873868Z",
     "start_time": "2024-10-09T15:45:06.750624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "models = {\n",
    "    # Default model\n",
    "    \"256\": [RecurrentSpaceNet(n_in=2, n_out=256, corr_across_space=True, scale=0.25, beta=0.5, device=device) for _ in range(n_models)],\n",
    "    \n",
    "    # Beta grid\n",
    "    \"256_0beta\": [RecurrentSpaceNet(n_in=2, n_out=256, corr_across_space=True, scale=0.25, beta=0., device=device) for _ in range(n_models)],\n",
    "    \"256_025beta\": [RecurrentSpaceNet(n_in=2, n_out=256, corr_across_space=True, scale=0.25, beta=0.25, device=device) for _ in range(n_models)],\n",
    "    \"256_075beta\": [RecurrentSpaceNet(n_in=2, n_out=256, corr_across_space=True, scale=0.25, beta=0.75, device=device) for _ in range(n_models)],\n",
    "    \n",
    "    # Scale grid\n",
    "    \"256_01scale\": [RecurrentSpaceNet(n_in=2, n_out=256, corr_across_space=True, scale=0.1, beta=0.5, device=device) for _ in range(n_models)],\n",
    "    \"256_05scale\": [RecurrentSpaceNet(n_in=2, n_out=256, corr_across_space=True, scale=0.5, beta=0.5, device=device) for _ in range(n_models)],\n",
    "    \n",
    "    # n grid\n",
    "    \"512\": [RecurrentSpaceNet(n_in=2, n_out=512, corr_across_space=True, scale=0.25, beta=0.5, device=device) for _ in range(n_models)],\n",
    "    \"1024\": [RecurrentSpaceNet(n_in=2, n_out=1024, corr_across_space=True, scale=0.25, beta=0.5, device=device) for _ in range(n_models)],\n",
    "}\n",
    "\n",
    "loss_histories = {name: [] for name in models.keys()}\n",
    "\n",
    "# --------------------- Training ----------------------\n",
    "\n",
    "for name, model_list in models.items():\n",
    "    \n",
    "    print(f\"Training {name}\")\n",
    "    for i, model in enumerate(model_list):\n",
    "        \n",
    "        print(f\"Model {i+1}\")\n",
    "        \n",
    "        # Initialize optimizer and dataset generator\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        genny = SimpleDatasetMaker()    \n",
    "        \n",
    "        if os.path.exists(os.path.join(model_path, f\"{name}_{i}.pt\")):\n",
    "            model = torch.load(os.path.join(model_path, f\"{name}_{i}.pt\"))\n",
    "            loss_history = np.load(os.path.join(model_path, f\"{name}_{i}_loss_history.npy\"))\n",
    "            loss_histories[name].append(loss_history)\n",
    "            continue\n",
    "        \n",
    "        loss_history = []\n",
    "        progress = tqdm(range(train_steps))\n",
    "        for k in progress:  \n",
    "            \n",
    "            # Create batch of trajectories\n",
    "            r, v = genny.generate_dataset(bs, timesteps, device=device)\n",
    "        \n",
    "            # Perform training step\n",
    "            loss = model.train_step(x=(v, r[:, 0]), y=r[:, 1:], optimizer=optimizer)\n",
    "        \n",
    "            loss_history.append(loss)\n",
    "            \n",
    "            if k % 10 == 0:\n",
    "                progress.set_description(f\"loss: {loss:>7f}\")\n",
    "                \n",
    "        models[name][i] = model\n",
    "        loss_histories[name].append(loss_history)\n",
    "\n",
    "        # Save model and loss history\n",
    "        torch.save(model, os.path.join(model_path, f\"{name}_{i}.pt\"))\n",
    "        np.save(os.path.join(model_path, f\"{name}_{i}_loss_history.npy\"), loss_history)\n"
   ],
   "id": "2d3b15214e510cf0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 256\n",
      "Model 1\n",
      "Training 256_0beta\n",
      "Model 1\n",
      "Training 256_025beta\n",
      "Model 1\n",
      "Training 256_075beta\n",
      "Model 1\n",
      "Training 256_01scale\n",
      "Model 1\n",
      "Training 256_05scale\n",
      "Model 1\n",
      "Training 512\n",
      "Model 1\n",
      "Training 1024\n",
      "Model 1\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Recurrent Network (context)",
   "id": "7c150148f4973a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T16:02:26.865204Z",
     "start_time": "2024-10-09T16:02:26.858290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ----------------------- Params -----------------------\n",
    "train_steps = 60000             # Number of training steps\n",
    "timesteps = 10                  # Length of trajectories\n",
    "bs = 64                         # Batch size\n",
    "lr = 1e-4                       # Learning rate\n",
    "n_models = 1                    # Number of models to train\n",
    "cmin = -2                       # Minimum context value\n",
    "cmax = 2                        # Maximum context value"
   ],
   "id": "fd0490104cf87413",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T16:20:50.817738Z",
     "start_time": "2024-10-09T16:02:38.974328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "models = {\n",
    "    \"256_context\": [RecurrentSpaceNet(n_in=3, n_out=256, corr_across_space=True, scale=0.25, beta=0.5, device=device, initial_state_size=3) for _ in range(n_models)],\n",
    "    \"256_context_not_initial\": [RecurrentSpaceNet(n_in=3, n_out=256, corr_across_space=True, scale=0.25, beta=0.5, device=device, initial_state_size=2) for _ in range(n_models)],\n",
    "    \n",
    "    # Beta grid\n",
    "    \"256_context_0beta\": [RecurrentSpaceNet(n_in=3, n_out=256, corr_across_space=True, scale=0.25, beta=0., device=device, initial_state_size=3) for _ in range(n_models)],\n",
    "    \"256_context_025beta\": [RecurrentSpaceNet(n_in=3, n_out=256, corr_across_space=True, scale=0.25, beta=0.25, device=device, initial_state_size=3) for _ in range(n_models)],\n",
    "    \"256_context_075beta\": [RecurrentSpaceNet(n_in=3, n_out=256, corr_across_space=True, scale=0.25, beta=0.75, device=device, initial_state_size=3) for _ in range(n_models)],\n",
    "}\n",
    "\n",
    "loss_histories = {name: [] for name in models.keys()}\n",
    "\n",
    "# --------------------- Training ----------------------\n",
    "\n",
    "for name, model_list in models.items():\n",
    "    \n",
    "    print(f\"Training {name}\")\n",
    "    for i, model in enumerate(model_list):\n",
    "        \n",
    "        print(f\"Model {i+1}\")\n",
    "        \n",
    "        context_in_initial = True if model.initial_state_size == 3 else False\n",
    "        \n",
    "        # Initialize optimizer and dataset generator\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        genny = SimpleDatasetMaker()    \n",
    "        \n",
    "        if os.path.exists(os.path.join(model_path, f\"{name}_{i}.pt\")):\n",
    "            model = torch.load(os.path.join(model_path, f\"{name}_{i}.pt\"))\n",
    "            loss_history = np.load(os.path.join(model_path, f\"{name}_{i}_loss_history.npy\"))\n",
    "            loss_histories[name].append(loss_history)\n",
    "            continue\n",
    "        \n",
    "        loss_history = []\n",
    "        progress = tqdm(range(train_steps))\n",
    "        for k in progress:  \n",
    "            \n",
    "            # Create batch of trajectories\n",
    "            r, v = genny.generate_dataset(bs, timesteps, device=device)\n",
    "            \n",
    "            # Get random contexts and use for all timesteps along a trajectory\n",
    "            c = torch.tensor(np.random.uniform(cmin, cmax, bs), dtype=torch.float32, device=device)\n",
    "            c = c[:, None, None] * torch.ones((1, timesteps - 1, 1), device=device)\n",
    "            \n",
    "            # Build initial input\n",
    "            if context_in_initial:\n",
    "                initial_input = torch.cat((r[:, 0], c[:, 0]), dim=-1)\n",
    "            else:\n",
    "                initial_input = r[:, 0]\n",
    "            \n",
    "            # Concatenate velocity and context\n",
    "            inputs = (torch.cat((v, c), dim=-1), initial_input)\n",
    "            labels = (r[:, 1:], c)\n",
    "        \n",
    "            # Perform training step\n",
    "            loss = model.train_step(x=inputs, y=labels, optimizer=optimizer)\n",
    "        \n",
    "            loss_history.append(loss)\n",
    "            \n",
    "            if k % 10 == 0:\n",
    "                progress.set_description(f\"loss: {loss:>7f}\")\n",
    "                \n",
    "        models[name][i] = model\n",
    "        loss_histories[name].append(loss_history)\n",
    "\n",
    "        # Save model and loss history\n",
    "        torch.save(model, os.path.join(model_path, f\"{name}_{i}.pt\"))\n",
    "        np.save(os.path.join(model_path, f\"{name}_{i}_loss_history.npy\"), loss_history)\n"
   ],
   "id": "9ec80affc7f82119",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 256_context\n",
      "Model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000619: 100%|██████████| 60000/60000 [16:38<00:00, 60.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 256_context_not_initial\n",
      "Model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.002729:   6%|▋         | 3797/60000 [01:33<22:59, 40.74it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 53\u001B[0m\n\u001B[1;32m     50\u001B[0m labels \u001B[38;5;241m=\u001B[39m (r[:, \u001B[38;5;241m1\u001B[39m:], c)\n\u001B[1;32m     52\u001B[0m \u001B[38;5;66;03m# Perform training step\u001B[39;00m\n\u001B[0;32m---> 53\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m loss_history\u001B[38;5;241m.\u001B[39mappend(loss)\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m10\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/Software/BSR/src/models.py:348\u001B[0m, in \u001B[0;36mRecurrentSpaceNet.train_step\u001B[0;34m(self, x, y, optimizer, **kwargs)\u001B[0m\n\u001B[1;32m    345\u001B[0m \u001B[38;5;124;03m\"\"\"Perform a single training step and returns the loss.\u001B[39;00m\n\u001B[1;32m    346\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    347\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m--> 348\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloss_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    349\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m    350\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m~/Software/BSR/src/models.py:330\u001B[0m, in \u001B[0;36mRecurrentSpaceNet.loss_fn\u001B[0;34m(self, x, ys, hidden_state, **kwargs)\u001B[0m\n\u001B[1;32m    328\u001B[0m labels \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mones_like(corr)\n\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m y \u001B[38;5;129;01min\u001B[39;00m ys:\n\u001B[0;32m--> 330\u001B[0m     labels \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcorrelation_function(y)\n\u001B[1;32m    331\u001B[0m labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m*\u001B[39m(\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbeta) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbeta \u001B[38;5;66;03m# normalize to [beta, 1] \u001B[39;00m\n\u001B[1;32m    333\u001B[0m \u001B[38;5;66;03m# Compute loss between the correlations and the labels\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Feedforward Network",
   "id": "99dbf739608c6235"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T12:36:32.645914Z",
     "start_time": "2024-10-10T12:36:32.637577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ----------------------- Params -----------------------\n",
    "train_steps = 60000             # Number of training steps\n",
    "bs = 64                         # Batch size\n",
    "lr = 1e-4                       # Learning rate\n",
    "n_models = 10                   # Number of models to train"
   ],
   "id": "aee821ac8923c15a",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T13:36:34.145896Z",
     "start_time": "2024-10-10T12:36:34.943347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "models = {\n",
    "    \"256_ff\": [SpaceNet(n_in=2, n_out=256, scale=0.25, beta=0.5, device=device) for _ in range(n_models)],\n",
    "    \"256_ff_01scale\": [SpaceNet(n_in=2, n_out=256, scale=0.1, beta=0.5, device=device) for _ in range(n_models)],\n",
    "    \"256_ff_05scale\": [SpaceNet(n_in=2, n_out=256, scale=0.5, beta=0.5, device=device) for _ in range(n_models)],\n",
    "    \"256_ff_0beta\": [SpaceNet(n_in=2, n_out=256, scale=0.25, beta=0, device=device) for _ in range(n_models)],\n",
    "    \"256_ff_025beta\": [SpaceNet(n_in=2, n_out=256, scale=0.25, beta=0.25, device=device) for _ in range(n_models)],\n",
    "    \"256_ff_075beta\": [SpaceNet(n_in=2, n_out=256, scale=0.25, beta=0.75, device=device) for _ in range(n_models)],\n",
    "}\n",
    "\n",
    "loss_histories = {name: [] for name in models.keys()}\n",
    "\n",
    "# --------------------- Training ----------------------\n",
    "\n",
    "for name, model_list in models.items():\n",
    "    \n",
    "    print(f\"Training {name}\")\n",
    "    for i, model in enumerate(model_list):\n",
    "        \n",
    "        print(f\"Model {i+1}\")\n",
    "        \n",
    "        # Initialize optimizer and dataset generator\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        genny = SimpleDatasetMaker()    \n",
    "        \n",
    "        if os.path.exists(os.path.join(model_path, f\"{name}_{i}.pt\")):\n",
    "            model = torch.load(os.path.join(model_path, f\"{name}_{i}.pt\"))\n",
    "            loss_history = np.load(os.path.join(model_path, f\"{name}_{i}_loss_history.npy\"))\n",
    "            loss_histories[name].append(loss_history)\n",
    "            continue\n",
    "        \n",
    "        loss_history = []\n",
    "        progress = tqdm(range(train_steps))\n",
    "        for k in progress:  \n",
    "            \n",
    "            # Create batch of positions\n",
    "            r = torch.tensor(np.random.uniform(-1, 1, (bs, 2)), dtype=torch.float32)\n",
    "        \n",
    "            # Perform training step\n",
    "            loss = model.train_step(x=r, y=r, optimizer=optimizer)\n",
    "        \n",
    "            loss_history.append(loss)\n",
    "            \n",
    "            if k % 10 == 0:\n",
    "                progress.set_description(f\"loss: {loss:>7f}\")\n",
    "                \n",
    "        models[name][i] = model\n",
    "        loss_histories[name].append(loss_history)\n",
    "\n",
    "        # Save model and loss history\n",
    "        torch.save(model, os.path.join(model_path, f\"{name}_{i}.pt\"))\n",
    "        np.save(os.path.join(model_path, f\"{name}_{i}_loss_history.npy\"), loss_history)\n"
   ],
   "id": "5e8950ab2d81c4ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 256_ff\n",
      "Model 1\n",
      "Model 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000151: 100%|██████████| 60000/60000 [00:49<00:00, 1205.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000151: 100%|██████████| 60000/60000 [00:48<00:00, 1225.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000161: 100%|██████████| 60000/60000 [00:39<00:00, 1503.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000152: 100%|██████████| 60000/60000 [00:43<00:00, 1371.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000150: 100%|██████████| 60000/60000 [00:47<00:00, 1255.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000147: 100%|██████████| 60000/60000 [00:44<00:00, 1337.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000149: 100%|██████████| 60000/60000 [00:50<00:00, 1198.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000159: 100%|██████████| 60000/60000 [01:10<00:00, 848.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000145: 100%|██████████| 60000/60000 [01:10<00:00, 849.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 256_ff_01scale\n",
      "Model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000502: 100%|██████████| 60000/60000 [01:04<00:00, 929.69it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000441: 100%|██████████| 60000/60000 [01:02<00:00, 955.90it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000404: 100%|██████████| 60000/60000 [00:57<00:00, 1035.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000503: 100%|██████████| 60000/60000 [01:00<00:00, 985.50it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000378: 100%|██████████| 60000/60000 [01:12<00:00, 831.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000435: 100%|██████████| 60000/60000 [00:55<00:00, 1079.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000423: 100%|██████████| 60000/60000 [01:02<00:00, 952.66it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000505: 100%|██████████| 60000/60000 [01:05<00:00, 914.27it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000406: 100%|██████████| 60000/60000 [01:08<00:00, 874.33it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000378: 100%|██████████| 60000/60000 [01:09<00:00, 859.14it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 256_ff_05scale\n",
      "Model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000135: 100%|██████████| 60000/60000 [01:11<00:00, 838.33it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000135: 100%|██████████| 60000/60000 [01:05<00:00, 917.56it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000137: 100%|██████████| 60000/60000 [01:10<00:00, 856.08it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000135: 100%|██████████| 60000/60000 [01:14<00:00, 807.78it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000137: 100%|██████████| 60000/60000 [00:59<00:00, 1016.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000136: 100%|██████████| 60000/60000 [00:52<00:00, 1142.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000135: 100%|██████████| 60000/60000 [01:00<00:00, 985.36it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000135: 100%|██████████| 60000/60000 [00:51<00:00, 1157.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000136: 100%|██████████| 60000/60000 [01:04<00:00, 931.15it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000139: 100%|██████████| 60000/60000 [00:50<00:00, 1188.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 256_ff_0beta\n",
      "Model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.001199: 100%|██████████| 60000/60000 [00:55<00:00, 1088.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.001189: 100%|██████████| 60000/60000 [01:26<00:00, 689.75it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.001178: 100%|██████████| 60000/60000 [01:36<00:00, 623.74it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.001194: 100%|██████████| 60000/60000 [01:11<00:00, 843.70it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.001174: 100%|██████████| 60000/60000 [01:20<00:00, 741.48it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.001167: 100%|██████████| 60000/60000 [00:58<00:00, 1017.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.001154: 100%|██████████| 60000/60000 [00:49<00:00, 1215.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.001176: 100%|██████████| 60000/60000 [00:57<00:00, 1050.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.001166: 100%|██████████| 60000/60000 [00:53<00:00, 1127.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.001172: 100%|██████████| 60000/60000 [01:01<00:00, 978.89it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 256_ff_025beta\n",
      "Model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000305: 100%|██████████| 60000/60000 [00:46<00:00, 1299.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000306: 100%|██████████| 60000/60000 [01:07<00:00, 891.22it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000304: 100%|██████████| 60000/60000 [00:50<00:00, 1179.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000311: 100%|██████████| 60000/60000 [01:03<00:00, 943.51it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000314: 100%|██████████| 60000/60000 [01:00<00:00, 999.40it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000307: 100%|██████████| 60000/60000 [01:16<00:00, 786.78it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000305: 100%|██████████| 60000/60000 [01:04<00:00, 924.71it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000306: 100%|██████████| 60000/60000 [01:08<00:00, 877.89it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000300: 100%|██████████| 60000/60000 [01:03<00:00, 939.49it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000303: 100%|██████████| 60000/60000 [00:48<00:00, 1237.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 256_ff_075beta\n",
      "Model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000064: 100%|██████████| 60000/60000 [00:47<00:00, 1260.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000062: 100%|██████████| 60000/60000 [01:14<00:00, 801.31it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000064: 100%|██████████| 60000/60000 [01:15<00:00, 799.24it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000060: 100%|██████████| 60000/60000 [00:55<00:00, 1089.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000064: 100%|██████████| 60000/60000 [01:07<00:00, 893.59it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000062: 100%|██████████| 60000/60000 [00:50<00:00, 1198.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000062: 100%|██████████| 60000/60000 [00:53<00:00, 1125.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000061: 100%|██████████| 60000/60000 [00:57<00:00, 1042.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000061: 100%|██████████| 60000/60000 [00:55<00:00, 1089.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000063: 100%|██████████| 60000/60000 [00:54<00:00, 1100.95it/s]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feedforward Network (context)",
   "id": "e5337c72f5bd1793"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T16:58:59.238713Z",
     "start_time": "2024-10-09T16:58:59.235015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ----------------------- Params -----------------------\n",
    "train_steps = 60000             # Number of training steps\n",
    "bs = 64                         # Batch size\n",
    "lr = 1e-4                       # Learning rate\n",
    "n_models = 1                    # Number of models to train\n",
    "cmin = -2                       # Minimum context value\n",
    "cmax = 2                        # Maximum context value"
   ],
   "id": "e8e6d2b44c1dc2d1",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T17:01:46.119491Z",
     "start_time": "2024-10-09T17:00:34.193397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "models = {\n",
    "    \"256_ff_context\": [SpaceNet(n_in=3, n_out=256, scale=0.25, beta=0.5, device=device) for _ in range(n_models)],\n",
    "}\n",
    "\n",
    "loss_histories = {name: [] for name in models.keys()}\n",
    "\n",
    "# --------------------- Training ----------------------\n",
    "\n",
    "for name, model_list in models.items():\n",
    "    \n",
    "    print(f\"Training {name}\")\n",
    "    for i, model in enumerate(model_list):\n",
    "        \n",
    "        print(f\"Model {i+1}\")\n",
    "        \n",
    "        # Initialize optimizer and dataset generator\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        genny = SimpleDatasetMaker()    \n",
    "        \n",
    "        if os.path.exists(os.path.join(model_path, f\"{name}_{i}.pt\")):\n",
    "            model = torch.load(os.path.join(model_path, f\"{name}_{i}.pt\"))\n",
    "            loss_history = np.load(os.path.join(model_path, f\"{name}_{i}_loss_history.npy\"))\n",
    "            loss_histories[name].append(loss_history)\n",
    "            continue\n",
    "        \n",
    "        loss_history = []\n",
    "        progress = tqdm(range(train_steps))\n",
    "        for k in progress:  \n",
    "            \n",
    "            # Create batch of positions and contexts            \n",
    "            r = torch.tensor(np.random.uniform(-1, 1, (bs, 2)), dtype=torch.float32)\n",
    "            c = torch.tensor(np.random.uniform(cmin, cmax, bs), dtype=torch.float32)[:, None]\n",
    "            inputs = torch.cat((r, c), dim=-1)\n",
    "            labels = (r, c)\n",
    "                \n",
    "            # Perform training step\n",
    "            loss = model.train_step(x=inputs, y=labels, optimizer=optimizer)\n",
    "        \n",
    "            loss_history.append(loss)\n",
    "            \n",
    "            if k % 10 == 0:\n",
    "                progress.set_description(f\"loss: {loss:>7f}\")\n",
    "                \n",
    "        models[name][i] = model\n",
    "        loss_histories[name].append(loss_history)\n",
    "\n",
    "        # Save model and loss history\n",
    "        torch.save(model, os.path.join(model_path, f\"{name}_{i}.pt\"))\n",
    "        np.save(os.path.join(model_path, f\"{name}_{i}_loss_history.npy\"), loss_history)\n"
   ],
   "id": "7a5e1f18ad5552f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 256_ff_context\n",
      "Model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000514: 100%|██████████| 60000/60000 [01:11<00:00, 834.45it/s] \n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c36188a3a17eabf4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
