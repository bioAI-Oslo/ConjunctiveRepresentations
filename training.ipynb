{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-09T16:58:48.787265Z",
     "start_time": "2024-10-09T16:58:45.982035Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import pdist, cdist\n",
    "from scipy.spatial import cKDTree\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import umap\n",
    "from sklearn.manifold import MDS\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from src.models import SpaceNet, RecurrentSpaceNet, Decoder\n",
    "from src.utils import ratemap_collage, SimpleDatasetMaker\n",
    "\n",
    "plt.rcdefaults()\n",
    "plt.style.use(\"figures/project_style.mplstyle\")\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T16:58:53.042216Z",
     "start_time": "2024-10-09T16:58:53.037774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "figure_path = os.path.join(os.getcwd(), \"figures\")\n",
    "model_path = os.path.join(os.getcwd(), \"models\")\n",
    "results_path = os.path.join(os.getcwd(), \"results\")"
   ],
   "id": "aa1282e69a1e7069",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Recurrent Network (no context)",
   "id": "804531ec282af839"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T09:19:24.758504Z",
     "start_time": "2024-10-09T09:19:24.754754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ----------------------- Params -----------------------\n",
    "train_steps = 60000         # Number of training steps\n",
    "timesteps = 10              # Length of trajectories\n",
    "bs = 64                     # Batch size\n",
    "lr = 1e-4                   # Learning rate\n",
    "n_models = 1                # Number of models to train"
   ],
   "id": "1e778adbda58f0f7",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T15:45:06.873868Z",
     "start_time": "2024-10-09T15:45:06.750624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "models = {\n",
    "    # Default model\n",
    "    \"256\": [RecurrentSpaceNet(n_in=2, n_out=256, corr_across_space=True, scale=0.25, beta=0.5, device=device) for _ in range(n_models)],\n",
    "    \n",
    "    # Beta grid\n",
    "    \"256_0beta\": [RecurrentSpaceNet(n_in=2, n_out=256, corr_across_space=True, scale=0.25, beta=0., device=device) for _ in range(n_models)],\n",
    "    \"256_025beta\": [RecurrentSpaceNet(n_in=2, n_out=256, corr_across_space=True, scale=0.25, beta=0.25, device=device) for _ in range(n_models)],\n",
    "    \"256_075beta\": [RecurrentSpaceNet(n_in=2, n_out=256, corr_across_space=True, scale=0.25, beta=0.75, device=device) for _ in range(n_models)],\n",
    "    \n",
    "    # Scale grid\n",
    "    \"256_01scale\": [RecurrentSpaceNet(n_in=2, n_out=256, corr_across_space=True, scale=0.1, beta=0.5, device=device) for _ in range(n_models)],\n",
    "    \"256_05scale\": [RecurrentSpaceNet(n_in=2, n_out=256, corr_across_space=True, scale=0.5, beta=0.5, device=device) for _ in range(n_models)],\n",
    "    \n",
    "    # n grid\n",
    "    \"512\": [RecurrentSpaceNet(n_in=2, n_out=512, corr_across_space=True, scale=0.25, beta=0.5, device=device) for _ in range(n_models)],\n",
    "    \"1024\": [RecurrentSpaceNet(n_in=2, n_out=1024, corr_across_space=True, scale=0.25, beta=0.5, device=device) for _ in range(n_models)],\n",
    "}\n",
    "\n",
    "loss_histories = {name: [] for name in models.keys()}\n",
    "\n",
    "# --------------------- Training ----------------------\n",
    "\n",
    "for name, model_list in models.items():\n",
    "    \n",
    "    print(f\"Training {name}\")\n",
    "    for i, model in enumerate(model_list):\n",
    "        \n",
    "        print(f\"Model {i+1}\")\n",
    "        \n",
    "        # Initialize optimizer and dataset generator\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        genny = SimpleDatasetMaker()    \n",
    "        \n",
    "        if os.path.exists(os.path.join(model_path, f\"{name}_{i}.pt\")):\n",
    "            model = torch.load(os.path.join(model_path, f\"{name}_{i}.pt\"))\n",
    "            loss_history = np.load(os.path.join(model_path, f\"{name}_{i}_loss_history.npy\"))\n",
    "            loss_histories[name].append(loss_history)\n",
    "            continue\n",
    "        \n",
    "        loss_history = []\n",
    "        progress = tqdm(range(train_steps))\n",
    "        for k in progress:  \n",
    "            \n",
    "            # Create batch of trajectories\n",
    "            r, v = genny.generate_dataset(bs, timesteps, device=device)\n",
    "        \n",
    "            # Perform training step\n",
    "            loss = model.train_step(x=(v, r[:, 0]), y=r[:, 1:], optimizer=optimizer)\n",
    "        \n",
    "            loss_history.append(loss)\n",
    "            \n",
    "            if k % 10 == 0:\n",
    "                progress.set_description(f\"loss: {loss:>7f}\")\n",
    "                \n",
    "        models[name][i] = model\n",
    "        loss_histories[name].append(loss_history)\n",
    "\n",
    "        # Save model and loss history\n",
    "        torch.save(model, os.path.join(model_path, f\"{name}_{i}.pt\"))\n",
    "        np.save(os.path.join(model_path, f\"{name}_{i}_loss_history.npy\"), loss_history)\n"
   ],
   "id": "2d3b15214e510cf0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 256\n",
      "Model 1\n",
      "Training 256_0beta\n",
      "Model 1\n",
      "Training 256_025beta\n",
      "Model 1\n",
      "Training 256_075beta\n",
      "Model 1\n",
      "Training 256_01scale\n",
      "Model 1\n",
      "Training 256_05scale\n",
      "Model 1\n",
      "Training 512\n",
      "Model 1\n",
      "Training 1024\n",
      "Model 1\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Recurrent Network (context)",
   "id": "7c150148f4973a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T16:02:26.865204Z",
     "start_time": "2024-10-09T16:02:26.858290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ----------------------- Params -----------------------\n",
    "train_steps = 60000             # Number of training steps\n",
    "timesteps = 10                  # Length of trajectories\n",
    "bs = 64                         # Batch size\n",
    "lr = 1e-4                       # Learning rate\n",
    "n_models = 1                    # Number of models to train\n",
    "cmin = -2                       # Minimum context value\n",
    "cmax = 2                        # Maximum context value"
   ],
   "id": "fd0490104cf87413",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T16:20:50.817738Z",
     "start_time": "2024-10-09T16:02:38.974328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "models = {\n",
    "    \"256_context\": [RecurrentSpaceNet(n_in=3, n_out=256, corr_across_space=True, scale=0.25, beta=0.5, device=device, initial_state_size=3) for _ in range(n_models)],\n",
    "    \"256_context_not_initial\": [RecurrentSpaceNet(n_in=3, n_out=256, corr_across_space=True, scale=0.25, beta=0.5, device=device, initial_state_size=2) for _ in range(n_models)],\n",
    "    \n",
    "    # Beta grid\n",
    "    \"256_context_0beta\": [RecurrentSpaceNet(n_in=3, n_out=256, corr_across_space=True, scale=0.25, beta=0., device=device, initial_state_size=3) for _ in range(n_models)],\n",
    "    \"256_context_025beta\": [RecurrentSpaceNet(n_in=3, n_out=256, corr_across_space=True, scale=0.25, beta=0.25, device=device, initial_state_size=3) for _ in range(n_models)],\n",
    "    \"256_context_075beta\": [RecurrentSpaceNet(n_in=3, n_out=256, corr_across_space=True, scale=0.25, beta=0.75, device=device, initial_state_size=3) for _ in range(n_models)],\n",
    "}\n",
    "\n",
    "loss_histories = {name: [] for name in models.keys()}\n",
    "\n",
    "# --------------------- Training ----------------------\n",
    "\n",
    "for name, model_list in models.items():\n",
    "    \n",
    "    print(f\"Training {name}\")\n",
    "    for i, model in enumerate(model_list):\n",
    "        \n",
    "        print(f\"Model {i+1}\")\n",
    "        \n",
    "        context_in_initial = True if model.initial_state_size == 3 else False\n",
    "        \n",
    "        # Initialize optimizer and dataset generator\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        genny = SimpleDatasetMaker()    \n",
    "        \n",
    "        if os.path.exists(os.path.join(model_path, f\"{name}_{i}.pt\")):\n",
    "            model = torch.load(os.path.join(model_path, f\"{name}_{i}.pt\"))\n",
    "            loss_history = np.load(os.path.join(model_path, f\"{name}_{i}_loss_history.npy\"))\n",
    "            loss_histories[name].append(loss_history)\n",
    "            continue\n",
    "        \n",
    "        loss_history = []\n",
    "        progress = tqdm(range(train_steps))\n",
    "        for k in progress:  \n",
    "            \n",
    "            # Create batch of trajectories\n",
    "            r, v = genny.generate_dataset(bs, timesteps, device=device)\n",
    "            \n",
    "            # Get random contexts and use for all timesteps along a trajectory\n",
    "            c = torch.tensor(np.random.uniform(cmin, cmax, bs), dtype=torch.float32, device=device)\n",
    "            c = c[:, None, None] * torch.ones((1, timesteps - 1, 1), device=device)\n",
    "            \n",
    "            # Build initial input\n",
    "            if context_in_initial:\n",
    "                initial_input = torch.cat((r[:, 0], c[:, 0]), dim=-1)\n",
    "            else:\n",
    "                initial_input = r[:, 0]\n",
    "            \n",
    "            # Concatenate velocity and context\n",
    "            inputs = (torch.cat((v, c), dim=-1), initial_input)\n",
    "            labels = (r[:, 1:], c)\n",
    "        \n",
    "            # Perform training step\n",
    "            loss = model.train_step(x=inputs, y=labels, optimizer=optimizer)\n",
    "        \n",
    "            loss_history.append(loss)\n",
    "            \n",
    "            if k % 10 == 0:\n",
    "                progress.set_description(f\"loss: {loss:>7f}\")\n",
    "                \n",
    "        models[name][i] = model\n",
    "        loss_histories[name].append(loss_history)\n",
    "\n",
    "        # Save model and loss history\n",
    "        torch.save(model, os.path.join(model_path, f\"{name}_{i}.pt\"))\n",
    "        np.save(os.path.join(model_path, f\"{name}_{i}_loss_history.npy\"), loss_history)\n"
   ],
   "id": "9ec80affc7f82119",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 256_context\n",
      "Model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000619: 100%|██████████| 60000/60000 [16:38<00:00, 60.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 256_context_not_initial\n",
      "Model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.002729:   6%|▋         | 3797/60000 [01:33<22:59, 40.74it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 53\u001B[0m\n\u001B[1;32m     50\u001B[0m labels \u001B[38;5;241m=\u001B[39m (r[:, \u001B[38;5;241m1\u001B[39m:], c)\n\u001B[1;32m     52\u001B[0m \u001B[38;5;66;03m# Perform training step\u001B[39;00m\n\u001B[0;32m---> 53\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m loss_history\u001B[38;5;241m.\u001B[39mappend(loss)\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m10\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/Software/BSR/src/models.py:348\u001B[0m, in \u001B[0;36mRecurrentSpaceNet.train_step\u001B[0;34m(self, x, y, optimizer, **kwargs)\u001B[0m\n\u001B[1;32m    345\u001B[0m \u001B[38;5;124;03m\"\"\"Perform a single training step and returns the loss.\u001B[39;00m\n\u001B[1;32m    346\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    347\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m--> 348\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloss_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    349\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m    350\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m~/Software/BSR/src/models.py:330\u001B[0m, in \u001B[0;36mRecurrentSpaceNet.loss_fn\u001B[0;34m(self, x, ys, hidden_state, **kwargs)\u001B[0m\n\u001B[1;32m    328\u001B[0m labels \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mones_like(corr)\n\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m y \u001B[38;5;129;01min\u001B[39;00m ys:\n\u001B[0;32m--> 330\u001B[0m     labels \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcorrelation_function(y)\n\u001B[1;32m    331\u001B[0m labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m*\u001B[39m(\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbeta) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbeta \u001B[38;5;66;03m# normalize to [beta, 1] \u001B[39;00m\n\u001B[1;32m    333\u001B[0m \u001B[38;5;66;03m# Compute loss between the correlations and the labels\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Feedforward Network",
   "id": "99dbf739608c6235"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T17:06:37.082597Z",
     "start_time": "2024-10-09T17:06:37.078887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ----------------------- Params -----------------------\n",
    "train_steps = 60000             # Number of training steps\n",
    "bs = 64                         # Batch size\n",
    "lr = 1e-4                       # Learning rate\n",
    "n_models = 1                    # Number of models to train"
   ],
   "id": "aee821ac8923c15a",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T17:07:38.491844Z",
     "start_time": "2024-10-09T17:06:48.617165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "models = {\n",
    "    \"256_ff\": [SpaceNet(n_in=2, n_out=256, scale=0.25, beta=0.5, device=device) for _ in range(n_models)],\n",
    "}\n",
    "\n",
    "loss_histories = {name: [] for name in models.keys()}\n",
    "\n",
    "# --------------------- Training ----------------------\n",
    "\n",
    "for name, model_list in models.items():\n",
    "    \n",
    "    print(f\"Training {name}\")\n",
    "    for i, model in enumerate(model_list):\n",
    "        \n",
    "        print(f\"Model {i+1}\")\n",
    "        \n",
    "        # Initialize optimizer and dataset generator\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        genny = SimpleDatasetMaker()    \n",
    "        \n",
    "        if os.path.exists(os.path.join(model_path, f\"{name}_{i}.pt\")):\n",
    "            model = torch.load(os.path.join(model_path, f\"{name}_{i}.pt\"))\n",
    "            loss_history = np.load(os.path.join(model_path, f\"{name}_{i}_loss_history.npy\"))\n",
    "            loss_histories[name].append(loss_history)\n",
    "            continue\n",
    "        \n",
    "        loss_history = []\n",
    "        progress = tqdm(range(train_steps))\n",
    "        for k in progress:  \n",
    "            \n",
    "            # Create batch of positions\n",
    "            r = torch.tensor(np.random.uniform(-1, 1, (bs, 2)), dtype=torch.float32)\n",
    "        \n",
    "            # Perform training step\n",
    "            loss = model.train_step(x=r, y=r, optimizer=optimizer)\n",
    "        \n",
    "            loss_history.append(loss)\n",
    "            \n",
    "            if k % 10 == 0:\n",
    "                progress.set_description(f\"loss: {loss:>7f}\")\n",
    "                \n",
    "        models[name][i] = model\n",
    "        loss_histories[name].append(loss_history)\n",
    "\n",
    "        # Save model and loss history\n",
    "        torch.save(model, os.path.join(model_path, f\"{name}_{i}.pt\"))\n",
    "        np.save(os.path.join(model_path, f\"{name}_{i}_loss_history.npy\"), loss_history)\n"
   ],
   "id": "5e8950ab2d81c4ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 256_ff\n",
      "Model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000147: 100%|██████████| 60000/60000 [00:49<00:00, 1203.60it/s]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feedforward Network (context)",
   "id": "e5337c72f5bd1793"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T16:58:59.238713Z",
     "start_time": "2024-10-09T16:58:59.235015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ----------------------- Params -----------------------\n",
    "train_steps = 60000             # Number of training steps\n",
    "bs = 64                         # Batch size\n",
    "lr = 1e-4                       # Learning rate\n",
    "n_models = 1                    # Number of models to train\n",
    "cmin = -2                       # Minimum context value\n",
    "cmax = 2                        # Maximum context value"
   ],
   "id": "e8e6d2b44c1dc2d1",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T17:01:46.119491Z",
     "start_time": "2024-10-09T17:00:34.193397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "models = {\n",
    "    \"256_ff_context\": [SpaceNet(n_in=3, n_out=256, scale=0.25, beta=0.5, device=device) for _ in range(n_models)],\n",
    "}\n",
    "\n",
    "loss_histories = {name: [] for name in models.keys()}\n",
    "\n",
    "# --------------------- Training ----------------------\n",
    "\n",
    "for name, model_list in models.items():\n",
    "    \n",
    "    print(f\"Training {name}\")\n",
    "    for i, model in enumerate(model_list):\n",
    "        \n",
    "        print(f\"Model {i+1}\")\n",
    "        \n",
    "        # Initialize optimizer and dataset generator\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        genny = SimpleDatasetMaker()    \n",
    "        \n",
    "        if os.path.exists(os.path.join(model_path, f\"{name}_{i}.pt\")):\n",
    "            model = torch.load(os.path.join(model_path, f\"{name}_{i}.pt\"))\n",
    "            loss_history = np.load(os.path.join(model_path, f\"{name}_{i}_loss_history.npy\"))\n",
    "            loss_histories[name].append(loss_history)\n",
    "            continue\n",
    "        \n",
    "        loss_history = []\n",
    "        progress = tqdm(range(train_steps))\n",
    "        for k in progress:  \n",
    "            \n",
    "            # Create batch of positions and contexts            \n",
    "            r = torch.tensor(np.random.uniform(-1, 1, (bs, 2)), dtype=torch.float32)\n",
    "            c = torch.tensor(np.random.uniform(cmin, cmax, bs), dtype=torch.float32)[:, None]\n",
    "            inputs = torch.cat((r, c), dim=-1)\n",
    "            labels = (r, c)\n",
    "                \n",
    "            # Perform training step\n",
    "            loss = model.train_step(x=inputs, y=labels, optimizer=optimizer)\n",
    "        \n",
    "            loss_history.append(loss)\n",
    "            \n",
    "            if k % 10 == 0:\n",
    "                progress.set_description(f\"loss: {loss:>7f}\")\n",
    "                \n",
    "        models[name][i] = model\n",
    "        loss_histories[name].append(loss_history)\n",
    "\n",
    "        # Save model and loss history\n",
    "        torch.save(model, os.path.join(model_path, f\"{name}_{i}.pt\"))\n",
    "        np.save(os.path.join(model_path, f\"{name}_{i}_loss_history.npy\"), loss_history)\n"
   ],
   "id": "7a5e1f18ad5552f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 256_ff_context\n",
      "Model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.000514: 100%|██████████| 60000/60000 [01:11<00:00, 834.45it/s] \n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c36188a3a17eabf4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
